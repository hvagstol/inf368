{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "We'll start by having a look at the data set. The ZooScanSet consists of 1,433,278 images of objects. Mostly classified as plankton, although significant parts of the data consist of *detritus*, *fiber detritus* or *badfocus__artefact* - as well as other less prominent categories that may not be called species. For the classifier, it will of course be necessary to recognize these so they're not mistaken for other species.\n",
    "\n",
    "From the **ZooScan** manual, available at [https://sites.google.com/view/piqv/instruments-manuals], we know that all images are produced using an instrument much like a flatbed scanner. We assume,therefore, that sizes are comparable between images, and that any size variance in the data is due to actual size variance or possibly technical/labelling errors.\n",
    "\n",
    "Images are all 8-bit single channel (gray scale) JPEG compressed images. This will need to be taken into consideration when using a pre-built architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe85bb231d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "taxa = pd.read_csv('../../data/zooscannet/ZooScanSet/taxa.csv', usecols=[\"objid\",\"taxon\"])\n",
    "\n",
    "# we first have a look at the data.\n",
    "taxa_distribution = taxa['taxon'].value_counts()\n",
    "\n",
    "# look at the frequency distribution\n",
    "#print(taxa_distribution)\n",
    "\n",
    "taxa['taxon'].value_counts().hist(bins=[0,250,500,1000,5000,10000,20000,50000,100000,250000,550000],\n",
    "                                  figsize=(16,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A closer look at the frequency distribution\n",
    "\n",
    "From the histogram above, we see that about 30 of 93 the data categories have less than 250 samples. If we include two more bins (< 1000 samples) we are at 51 of 93 bins. There are problems with this rather strong inbalance in the data:\n",
    "\n",
    "* Model training will strongly emphasize the dominant classes\n",
    "* For inference or testing, it is likely that we'll miss out on many of the rare classes, poor recall. This will be both due to lack of samples for evaluation (i.e. if you select 2% of 39 samples of Ctenophora it won't really tell you a lot) and a the imbalance in training.\n",
    "* The model would also in a sence perform well (high accuracy) if it strongly prefers the dominant classes for classification, after all predicting \"detritus\" in any case would be correct in over 1/3 of the samples. We may be wary of many false positives for the dominant classes - a low precision.\n",
    "\n",
    "### Handling the class imbalance\n",
    "(Inspired by [https://towardsdatascience.com/deep-learning-unbalanced-training-data-solve-it-like-this-6c528e9efea6])\n",
    "\n",
    "We have a few options:\n",
    "* Cull the dominant categories down to the frequency of the less common ones\n",
    "* Resample the less common categories to reuse the data\n",
    "* Grow the less common categories by synthetisizing samples. This would be like a data augmentation, though selectively applied where it is perceived to be needed.\n",
    "\n",
    "The first thing we can do, for starters, is to reduce the problem somewhat by only including the forty most abundant categories as suggested in the assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['detritus', 'Calanoida', 'badfocus__artefact', 'fiber__detritus',\n",
      "       'Oithonidae', 'Acartiidae', 'Chaetognatha', 'Calanidae', 'Evadne',\n",
      "       'Oikopleuridae', 'Phaeodaria', 'egg__other', 'Ostracoda',\n",
      "       'Coscinodiscus', 'multiple__other', 'Oncaeidae', 'bubble',\n",
      "       'Limacinidae', 'Corycaeidae', 'nauplii__Crustacea', 'cyphonaute',\n",
      "       'Temoridae', 'Salpida', 'Penilia', 'Noctiluca', 'zoea__Decapoda',\n",
      "       'nauplii__Cirripedia', 'Foraminifera', 'nectophore__Diphyidae',\n",
      "       'Brachyura', 'tail__Appendicularia', 'Centropagidae', 'Eucalanidae',\n",
      "       'Haloptilus', 'Bivalvia__Mollusca', 'calyptopsis', 'Decapoda',\n",
      "       'artefact', 'Doliolida', 'eudoxie__Diphyidae'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe85ba632b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only the most common categories please\n",
    "top_taxa_labels = taxa_distribution[:40]\n",
    "print(top_taxa_labels.index)\n",
    "\n",
    "# reduce the data set to this\n",
    "reduced = taxa.loc[taxa['taxon'].isin(top_taxa_labels.index)]\n",
    "\n",
    "# have a look at the new distribution as above\n",
    "\n",
    "#print(reduced['taxon'].value_counts())\n",
    "\n",
    "reduced['taxon'].value_counts().hist(bins=[0,250,500,1000,5000,10000,20000,50000,100000,250000,550000],\n",
    "                                  figsize=(16,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will use the first option above. We will generate balanced test sets by down sampling the bigger ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detritus - 100\n",
      "Calanoida - 100\n",
      "badfocus__artefact - 100\n",
      "fiber__detritus - 100\n",
      "Oithonidae - 100\n",
      "Acartiidae - 100\n",
      "Chaetognatha - 100\n",
      "Calanidae - 100\n",
      "Evadne - 100\n",
      "Oikopleuridae - 100\n",
      "Phaeodaria - 100\n",
      "egg__other - 100\n",
      "Ostracoda - 100\n",
      "Coscinodiscus - 100\n",
      "multiple__other - 100\n",
      "Oncaeidae - 100\n",
      "bubble - 100\n",
      "Limacinidae - 100\n",
      "Corycaeidae - 100\n",
      "nauplii__Crustacea - 100\n",
      "cyphonaute - 100\n",
      "Temoridae - 100\n",
      "Salpida - 100\n",
      "Penilia - 100\n",
      "Noctiluca - 100\n",
      "zoea__Decapoda - 100\n",
      "nauplii__Cirripedia - 100\n",
      "Foraminifera - 100\n",
      "nectophore__Diphyidae - 100\n",
      "Brachyura - 100\n",
      "tail__Appendicularia - 100\n",
      "Centropagidae - 100\n",
      "Eucalanidae - 100\n",
      "Haloptilus - 100\n",
      "Bivalvia__Mollusca - 100\n",
      "calyptopsis - 100\n",
      "Decapoda - 100\n",
      "artefact - 100\n",
      "Doliolida - 100\n",
      "eudoxie__Diphyidae - 100\n"
     ]
    }
   ],
   "source": [
    "# downsample the data to a fully balanced set\n",
    "\n",
    "downsampled = pd.DataFrame()\n",
    "for label in top_taxa_labels.index:\n",
    "    \n",
    "    this_category = reduced.loc[reduced['taxon'] == label].sample(n=100) #using a low n for demo, running code uses 3455\n",
    "    downsampled = pd.concat([downsampled, this_category])\n",
    "    print(label + ' - ' + str(np.shape(this_category)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/havard/anaconda3/envs/inf368/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "X = downsampled[['objid']]\n",
    "y = downsampled[['taxon']]\n",
    "\n",
    "#X = downsampled\n",
    "#y = pd.get_dummies(downsampled['taxon'], sparse=False).values\n",
    "\n",
    "le.fit(np.unique(downsampled['taxon']))\n",
    "lb.fit(le.transform(np.unique(downsampled['taxon'])))\n",
    "\n",
    "#y = le.transform(downsampled['taxon'])\n",
    "#y = lb.fit_transform(y)\n",
    "\n",
    "# split into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.6, random_state=42, stratify=y)\n",
    "#print(le.inverse_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "      \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Data generator for image data, based on:\n",
    "    https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "    Modified to be more pandas friendly and to import images using pillow\n",
    "    \"\"\"\n",
    "\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, lenc, lbin, batch_size=32, dim=(224,224), n_channels=3,\n",
    "                 n_classes=93, shuffle=False, testing=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.lenc = lenc\n",
    "        self.lbin = lbin\n",
    "        self.basepath = '../../data/zooscannet/ZooScanSet/imgs/'\n",
    "        self.testing = testing\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        \n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs.index[k] for k in indexes]                \n",
    "        \n",
    "        # we need to pass the index somehow as well..\n",
    "        \n",
    "        # Generate data\n",
    "        if (self.testing):\n",
    "             X=self.__data_generation(list_IDs_temp)\n",
    "             return X\n",
    "        else:\n",
    "            X, y = self.__data_generation(list_IDs_temp)\n",
    "            return X, y\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def load_image(self, infilename ) :\n",
    "        img = Image.open( infilename )\n",
    "        img.load()\n",
    "        #not good resizing, prbly\n",
    "        img = img.resize((224,224), Image.BICUBIC)        \n",
    "        data = np.asarray( img, dtype=\"int32\").reshape(224,224,1)\n",
    "        return data\n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))\n",
    "        y = np.empty((self.batch_size, self.n_classes), dtype=str)\n",
    "\n",
    "        # Generate data\n",
    "        #print(self.labels)\n",
    "        #print(list_IDs_temp)\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample            \n",
    "            path = self.basepath + str(self.labels.loc[ID]['taxon']) + '/' + str(self.list_IDs.loc[ID]['objid']) + '.jpg'\n",
    "            #print(path)\n",
    "            img = self.load_image(path)\n",
    "            X[i,] = img\n",
    "\n",
    "            if (self.testing == False):\n",
    "                # Store class, first need to one hot encode it using the received encoders\n",
    "                named_class=self.labels.loc[ID]['taxon']\n",
    "                labeled_class=self.lenc.transform([named_class])\n",
    "                onehot_class =  self.lbin.transform([labeled_class])                        \n",
    "                y[i] = onehot_class\n",
    "            \n",
    "        if (self.testing):\n",
    "            return X\n",
    "        else:\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2400 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/havard/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36/37 [============================>.] - ETA: 12s - loss: 3.4614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7d8a1bd3e025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     workers=1,epochs=1)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#y_fit = model.predict(X_test, batch_size=256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                  \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                                  str(generator_output))\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/inf368/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "print('Training on '+str(np.shape(X_train)[0]) +' samples')\n",
    "# Parameters\n",
    "params = {'dim': (224,224),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 40,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False}\n",
    "\n",
    "params_test = {'dim': (224,224),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 40,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False}\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(40, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "training_generator = DataGenerator(X_train, y_train, le, lb, **params)\n",
    "validation_generator = DataGenerator(X_test, y_test, le, lb, **params)\n",
    "testing_generator = DataGenerator(X_test, y_test, le, lb, testing=True, **params_test)\n",
    "\n",
    "\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=1,epochs=1)\n",
    "\n",
    "#y_fit = model.predict(X_test, batch_size=256)\n",
    "#performance_eval('resnet',y_fit.argmax(axis=1), y_test.argmax(axis=1))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/pool.py\", line 405, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/pool.py\", line 246, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/havard/anaconda3/envs/inf368/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_fit = model.predict_generator(generator=testing_generator, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1600, 128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-430004c1a456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mperformance_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mperformance_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/inf368/code_repository/ex1/helpers.py\u001b[0m in \u001b[0;36mperformance_eval\u001b[0;34m(title, y_fit, y_target)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_classification.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/inf368/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \"\"\"\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/inf368/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/inf368/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1600, 128]"
     ]
    }
   ],
   "source": [
    "from helpers import performance_eval\n",
    "\n",
    "performance_eval('resnet', le.inverse_transform(y_fit.argmax(axis=1)),np.array(y_test.values).ravel())[0:test_length]\n",
    "\n",
    "\n",
    "#print (le.inverse_transform(y_fit.argmax(axis=1)))\n",
    "#print (np.array(y_test.values).ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
